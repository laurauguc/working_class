{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Parsing Code For NYT"
      ],
      "metadata": {
        "id": "Cn169m6eQP2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from docx import Document\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "folder_path = '/Users/jingguo/Desktop/NYT'\n",
        "\n",
        "# Collect DOCX files sorted numerically\n",
        "docx_files = sorted(\n",
        "    [f for f in os.listdir(folder_path) if f.endswith('.DOCX') and not f.startswith('~')],\n",
        "    key=lambda x: int(x.split('.')[0].split('-')[0])\n",
        ")\n",
        "\n",
        "# Helper to break text into article blocks\n",
        "def extract_article_blocks(text):\n",
        "    return [a.strip() for a in text.split(\"End of Document\") if a.strip()]\n",
        "\n",
        "# Logic to extract metadata + body from each article block\n",
        "def parse_article(text_block):\n",
        "    lines = [line.strip() for line in text_block.split(\"\\n\") if line.strip()]\n",
        "\n",
        "    #  Title before \"The New York Times\"\n",
        "    title = None\n",
        "    for i, line in enumerate(lines):\n",
        "        if \"The New York Times\" in line:\n",
        "            if i > 0:\n",
        "                candidate = lines[i-1]\n",
        "                if candidate.lower() not in [\"user name\", \"no headline in original\"]:\n",
        "                    title = candidate\n",
        "            break\n",
        "    title = title or \"No headline\"\n",
        "\n",
        "    #  Date\n",
        "    date = next((line for line in lines if re.search(r\"\\d{4}\", line)), None)\n",
        "\n",
        "    #  Section and Length\n",
        "    section = next((line for line in lines if line.lower().startswith(\"section\")), None)\n",
        "    length = next((line for line in lines if line.lower().startswith(\"length\")), None)\n",
        "\n",
        "    #  Body text\n",
        "    body = \"\"\n",
        "    if \"Body\" in lines:\n",
        "        body_start = lines.index(\"Body\") + 1\n",
        "        body_end = lines.index(\"Graphic\") if \"Graphic\" in lines else len(lines)\n",
        "        body_lines = lines[body_start:body_end]\n",
        "        body = \"\\n\".join(body_lines).strip()\n",
        "\n",
        "    return {\n",
        "        \"title\": title,\n",
        "        \"date\": date,\n",
        "        \"section\": section,\n",
        "        \"length\": length,\n",
        "        \"body\": body\n",
        "    }\n",
        "\n",
        "#  Parse all files\n",
        "records = []\n",
        "for file in tqdm(docx_files, desc=\"Parsing DOCX files\"):\n",
        "    doc = Document(os.path.join(folder_path, file))\n",
        "    full_text = \"\\n\".join(p.text for p in doc.paragraphs)\n",
        "    articles = extract_article_blocks(full_text)\n",
        "\n",
        "    for article in articles:\n",
        "        parsed = parse_article(article)\n",
        "        parsed[\"source_file\"] = file\n",
        "        records.append(parsed)\n",
        "\n",
        "#  Convert to DataFrame and save\n",
        "df = pd.DataFrame(records)\n",
        "output_path = os.path.join(folder_path, \"nyt_1980_2024_parsed_clean.csv\")\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "Trd9dlAXQqYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing Code For Other Publishers"
      ],
      "metadata": {
        "id": "aUqc5RYbQLet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from docx import Document\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Setup ===\n",
        "folder_path = '/Users/jingguo/Desktop/OPT/NLP/NYT/Archive'\n",
        "output_csv = os.path.join(folder_path, 'publisher_articles_parsed.csv')\n",
        "\n",
        "# === File list ===\n",
        "docx_files = sorted([\n",
        "    f for f in os.listdir(folder_path)\n",
        "    if f.endswith('.DOCX') and not f.startswith('~')\n",
        "], key=lambda x: int(x.split('.')[0].split('(')[1].split(')')[0]))\n",
        "\n",
        "def extract_article_blocks(text):\n",
        "    # Split by \"End of Document\"\n",
        "    return [a.strip() for a in text.split(\"End of Document\") if a.strip()]\n",
        "\n",
        "def parse_article(text_block):\n",
        "    lines = [line.strip() for line in text_block.split(\"\\n\") if line.strip()]\n",
        "\n",
        "    # Title line before \"The New York Times\" or fallback\n",
        "    title = None\n",
        "    for i, line in enumerate(lines):\n",
        "        if \"The New York Times\" in line:\n",
        "            if i > 0:\n",
        "                candidate = lines[i - 1]\n",
        "                if candidate.lower() not in [\"user name\", \"no headline in original\"]:\n",
        "                    title = candidate\n",
        "            break\n",
        "    title = title or \"No headline\"\n",
        "\n",
        "    # Date line\n",
        "    date = next((line for line in lines if any(month in line for month in [\n",
        "        \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",\n",
        "        \"August\", \"September\", \"October\", \"November\", \"December\"\n",
        "    ])), None)\n",
        "\n",
        "    # Section and Length lines\n",
        "    section = next((line for line in lines if line.lower().startswith(\"section\")), None)\n",
        "    length = next((line for line in lines if line.lower().startswith(\"length\")), None)\n",
        "\n",
        "    # Body extraction\n",
        "    body = \"\"\n",
        "    if \"Body\" in lines:\n",
        "        body_start = lines.index(\"Body\") + 1\n",
        "        if \"Graphic\" in lines:\n",
        "            body_end = lines.index(\"Graphic\")\n",
        "            body_lines = lines[body_start:body_end]\n",
        "        else:\n",
        "            body_lines = lines[body_start:]\n",
        "        body = \"\\n\".join(body_lines).strip()\n",
        "\n",
        "    return {\n",
        "        \"title\": title,\n",
        "        \"date\": date,\n",
        "        \"section\": section,\n",
        "        \"length\": length,\n",
        "        \"body\": body\n",
        "    }\n",
        "\n",
        "# === Parse all files ===\n",
        "records = []\n",
        "for file in tqdm(docx_files, desc=\"Parsing publisher DOCX files\"):\n",
        "    doc = Document(os.path.join(folder_path, file))\n",
        "    full_text = \"\\n\".join(p.text for p in doc.paragraphs)\n",
        "    articles = extract_article_blocks(full_text)\n",
        "\n",
        "    for article in articles:\n",
        "        parsed = parse_article(article)\n",
        "        parsed[\"source_file\"] = file\n",
        "        records.append(parsed)\n",
        "\n",
        "# === Save output ===\n",
        "df = pd.DataFrame(records)\n",
        "print(f\"‚úÖ Total articles parsed: {len(df)}\")\n",
        "df.to_csv(output_csv, index=False)\n",
        "print(f\"üìÅ Saved to: {output_csv}\")\n"
      ],
      "metadata": {
        "id": "YyYEHehrQTep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging"
      ],
      "metadata": {
        "id": "_eyIKbOTQm6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === 1. File paths ===\n",
        "nyt_path = \"/Users/jingguo/Desktop/OPT/NLP/NYT/nyt_1980_2024_articles_block_parsed.csv\"\n",
        "other_path = \"/Users/jingguo/Desktop/OPT/NLP/NYT/Archive/publisher_articles_parsed.csv\"\n",
        "output_path = \"/Users/jingguo/Desktop/OPT/NLP/NYT/combined_articles_1980_2024.csv\"\n",
        "\n",
        "# === 2. Load datasets ===\n",
        "df_nyt = pd.read_csv(nyt_path)\n",
        "df_other = pd.read_csv(other_path)\n",
        "\n",
        "# Optional: Tag source\n",
        "df_nyt[\"source_group\"] = \"NYT\"\n",
        "df_other[\"source_group\"] = \"Other Publishers\"\n",
        "\n",
        "# === 3. Merge ===\n",
        "df_combined = pd.concat([df_nyt, df_other], ignore_index=True)\n",
        "\n",
        "# === 4. Save ===\n",
        "df_combined.to_csv(output_path, index=False)\n",
        "print(f\"‚úÖ Combined CSV saved to: {output_path}\")\n",
        "print(f\"üî¢ Total articles: {len(df_combined)}\")\n"
      ],
      "metadata": {
        "id": "H-MnEMMKQo1O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}